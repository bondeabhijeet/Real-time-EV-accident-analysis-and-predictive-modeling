{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabulate\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Intermediate.csv file\n",
    "\n",
    "df = pd.read_csv(\"Intermediate.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align: center; font-size: 20px;color: #333; padding: 10px; background-color: #FFFFFF; border-radius: 5px;\">\n",
    "    <strong> 9 A. Filling missing latitude and longitude using external library</strong>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ðŸš¨ DO NOT RUN THIS THE FOLLOWING CELL ðŸš¨**  \n",
    "âš ï¸ This operation takes approx **21 days** to complete if running on a single PC!, threading is not allowed to this API, nor is request.session() âš ï¸  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "# Creating 3 new columns in the dataframe to get information from a api based on the Addresses column we created before -> we fetch Latitude, Longitude and Location from the API\n",
    "df['NLat'] = ''\n",
    "df['NLong'] = ''\n",
    "df['Location'] = ''\n",
    "\n",
    "for i in range(len(df)):\n",
    "  if not (df.notna(df['LATITUDE'][i]) and pd.notna(df['LONGITUDE'][i]) and pd.notna(df['ZIP CODE'][i])):\n",
    "\n",
    "    test = df.loc[i, \"Addresses\"]\n",
    "    url = f\"https://nominatim.openstreetmap.org/search?format=json&q={test}\"\n",
    "\n",
    "    # Mimicing a mozilla firefox browser\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36 Brave/91.0.4472.124'\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    # If there is a valid reponse, then extracting Latitude, Longitude, and Display name (Location/Address) and filling the newly created columns with this data\n",
    "    if response.status_code == 200:\n",
    "      if len(response.json()) == 1:\n",
    "        df.loc[i, \"NLat\"] = response.json()[0]['lat']\n",
    "        df.loc[i, \"NLong\"] = response.json()[0]['lon']\n",
    "        df.loc[i, \"Location\"] = response.json()[0]['display_name']\n",
    "      if len(response.json()) > 1:\n",
    "        df.loc[i, \"NLat\"] = response.json()[0]['lat']\n",
    "        df.loc[i, \"NLong\"] = response.json()[0]['lon']\n",
    "        df.loc[i, \"Location\"] = response.json()[0]['display_name']\n",
    "    time.sleep(1)   # Sleeping for 1 second as the API does not allow more than 1 request per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a file the whole processed data after collecting information from the API\n",
    "\n",
    "df.to_csv('Intermediate2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "**End Of DataCleaning2.ipynb file Continue to DataCleaning3.ipynb file**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
